{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36828a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['The first words that come out', 'And I can see this song will be about you', \"I can't believe that I can breathe without you\"]\n",
      "전처리 후 데이터 개수: 175814\n",
      "전처리 후 Examples:\n",
      " ['<start> the first words that come out <end>', '<start> and i can see this song will be about you <end>', '<start> i can t believe that i can breathe without you <end>']\n",
      "Total words: 27496\n",
      "Tensor shape: (175814, 42)\n",
      "Source input shape: (175814, 41)\n",
      "Target input shape: (175814, 41)\n",
      "Train 데이터 크기: (158232, 41)\n",
      "Validation 데이터 크기: (17582, 41)\n",
      "Epoch 1/15\n",
      "618/618 [==============================] - 549s 882ms/step - loss: 1.4359 - val_loss: 1.2119\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.21189, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "618/618 [==============================] - 549s 888ms/step - loss: 1.1727 - val_loss: 1.1426\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.21189 to 1.14255, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "618/618 [==============================] - 548s 887ms/step - loss: 1.1103 - val_loss: 1.0933\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.14255 to 1.09328, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "618/618 [==============================] - 551s 891ms/step - loss: 1.0618 - val_loss: 1.0571\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.09328 to 1.05710, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "618/618 [==============================] - 549s 889ms/step - loss: 1.0204 - val_loss: 1.0271\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.05710 to 1.02714, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "618/618 [==============================] - 551s 891ms/step - loss: 0.9828 - val_loss: 1.0013\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.02714 to 1.00132, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "618/618 [==============================] - 549s 888ms/step - loss: 0.9484 - val_loss: 0.9801\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.00132 to 0.98014, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "618/618 [==============================] - 550s 890ms/step - loss: 0.9161 - val_loss: 0.9606\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.98014 to 0.96062, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "618/618 [==============================] - 551s 891ms/step - loss: 0.8861 - val_loss: 0.9447\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.96062 to 0.94475, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15\n",
      "618/618 [==============================] - 551s 891ms/step - loss: 0.8582 - val_loss: 0.9305\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.94475 to 0.93054, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "618/618 [==============================] - 551s 892ms/step - loss: 0.8327 - val_loss: 0.9181\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.93054 to 0.91808, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "618/618 [==============================] - 552s 893ms/step - loss: 0.8092 - val_loss: 0.9077\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.91808 to 0.90774, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "618/618 [==============================] - 553s 894ms/step - loss: 0.7876 - val_loss: 0.8998\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.90774 to 0.89982, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "618/618 [==============================] - 552s 893ms/step - loss: 0.7677 - val_loss: 0.8926\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.89982 to 0.89264, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15\n",
      "618/618 [==============================] - 552s 893ms/step - loss: 0.7494 - val_loss: 0.8865\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.89264 to 0.88653, saving model to best_lyrics_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_lyrics_model/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 Validation Loss: 0.8865\n",
      "목표 달성 여부 (2.2 이하): True\n",
      "\n",
      "==================================================\n",
      "가사 생성 결과 (평가기준 2)\n",
      "==================================================\n",
      "\n",
      "입력: <start> i love\n",
      "생성: start i love <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "입력: <start> i want\n",
      "생성: start i want <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "입력: <start> you are\n",
      "생성: start you are <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "입력: <start> we can\n",
      "생성: start we can <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "==================================================\n",
      "PDF 예시 형식 테스트\n",
      "==================================================\n",
      "start i love <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "==================================================\n",
      "평가 기준 체크\n",
      "==================================================\n",
      "1. 데이터 전처리: 특수문자 제거 ✓, 토크나이저 생성 ✓, 패딩 처리 ✓\n",
      "2. 텍스트 생성: 해석 가능한 문장 생성 (위 결과 참조)\n",
      "3. 안정적 학습: Validation Loss = 0.8865 (목표: 2.2 이하)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import zipfile\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# 0. zip 파일 압축 해제 \n",
    "zip_files = glob.glob('/content/*.zip')\n",
    "if zip_files:\n",
    "    print(f\"찾은 zip 파일: {zip_files}\")\n",
    "    for zip_file in zip_files:\n",
    "        if 'lyric' in zip_file.lower():\n",
    "            print(f\"압축 해제 중: {zip_file}\")\n",
    "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall('/content/')\n",
    "            print(\"압축 해제 완료!\")\n",
    "            break\n",
    "\n",
    "# 1. 데이터 읽어오기 \n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])\n",
    "\n",
    "# 2. 데이터 정제 (평가기준 1: 특수문자 제거, 토크나이저 생성, 패딩 처리)\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()  # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)  # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자를 스페이스 1개로 치환\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "# 수정: 너무 긴 문장만 제거 (40개 토큰 이하로 늘림)\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessed_sentence) == 0:\n",
    "        continue\n",
    "    # 수정: 40개 토큰 이하로 늘림 (더 많은 데이터 확보)\n",
    "    if len(preprocessed_sentence.split()) <= 40:\n",
    "        corpus.append(\"<start> \" + preprocessed_sentence + \" <end>\")\n",
    "\n",
    "print(\"전처리 후 데이터 개수:\", len(corpus))\n",
    "print(\"전처리 후 Examples:\\n\", corpus[:3])\n",
    "\n",
    "# 3. 평가기준 1: 토크나이저 생성\n",
    "# 수정: 단어장 크기 12,000 이상 \n",
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(num_words=12000,  # 수정: 12,000 단어로 제한\n",
    "                          filters='#$%&()*+-./:;<=>@[\\\\]^_`{|}~\\t\\n',  # 수정: ! , ? 를 필터에서 제외\n",
    "                          oov_token=\"<unk>\")  # Out-Of-Vocabulary 토큰\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # 패딩 처리 (평가기준 1)\n",
    "    tensor = pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    print(\"Total words:\", len(tokenizer.word_index))\n",
    "    print(\"Tensor shape:\", tensor.shape)\n",
    "    \n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "\n",
    "# 4. 입력과 레이블 분리\n",
    "# 소스 문장 (입력): <start> ~ 마지막에서 두 번째 토큰까지\n",
    "# 타겟 문장 (레이블): 두 번째 토큰 ~ <end>까지\n",
    "src_input = tensor[:, :-1]\n",
    "tgt_input = tensor[:, 1:]\n",
    "\n",
    "print(\"Source input shape:\", src_input.shape)\n",
    "print(\"Target input shape:\", tgt_input.shape)\n",
    "\n",
    "# 5. 평가 데이터셋 분리 (수정: 10%로 줄여서 학습 데이터 더 확보)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                            tgt_input,\n",
    "                                                            test_size=0.1,  # 수정: 10% 평가 데이터 (90% 학습) - 학습량 늘려봄\n",
    "                                                            random_state=42)\n",
    "\n",
    "print(\"Train 데이터 크기:\", enc_train.shape)\n",
    "print(\"Validation 데이터 크기:\", enc_val.shape)\n",
    "\n",
    "# 6. 데이터셋 구성\n",
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256  # 수정: 배치 크기 조정 (예시 코드 참고)\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# 7. 평가기준 3: 안정적 학습을 위한 모델 구성\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        # 수정: LSTM 레이어 2개 추가 (안정적 학습)\n",
    "        self.lstm_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.lstm_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        # 추가: Dropout으로 과적합 방지\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.lstm_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.lstm_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 수정: Embedding Size와 Hidden Size 조절 (예시 코드 권장사항)\n",
    "embedding_size = 256  # 수정: 임베딩 크기 증가\n",
    "hidden_size = 1024    # 수정: Hidden size 증가\n",
    "\n",
    "lyricist = TextGenerator(vocab_size=VOCAB_SIZE, \n",
    "                         embedding_size=embedding_size, \n",
    "                         hidden_size=hidden_size)  # 수정: 변수명을 lyricist로 변경\n",
    "\n",
    "# 8. Loss 함수 \n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "# 9. 학습 과정 정의\n",
    "# 수정: learning rate 조정\n",
    "lyricist.compile(loss=loss, \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "# 10. 평가기준 3: 안정적 학습을 위한 콜백 설정\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping: validation loss 2.2 이하 목표\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,  # 5 에포크 동안 개선 없으면 중단\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 수정: 서브클래스 모델은 SavedModel 형식으로 저장\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_lyrics_model',  # 수정: .h5 제거 (SavedModel 형식)\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_format='tf',  # 추가: TensorFlow SavedModel 형식\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 11. 모델 학습 (수정: 에포크 줄이고 데이터로 보완)\n",
    "history = lyricist.fit(dataset, \n",
    "                       epochs=15,  # 수정: 30 → 15로 줄임 (데이터가 충분하므로)\n",
    "                       validation_data=(enc_val, dec_val),\n",
    "                       callbacks=[early_stopping, checkpoint],\n",
    "                       verbose=1)\n",
    "\n",
    "# 12. 학습 결과 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.axhline(y=2.2, color='r', linestyle='--', label='Target (2.2)')  # 목표선\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n최종 Validation Loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(f\"목표 달성 여부 (2.2 이하): {min(history.history['val_loss']) <= 2.2}\")\n",
    "\n",
    "# 13. 텍스트 생성 함수 \n",
    "def generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20):\n",
    "    # 테스트를 위한 입력 문장 전처리\n",
    "    test_sentence = preprocess_sentence(init_sentence)\n",
    "    \n",
    "    # 정수 시퀀스로 변환\n",
    "    test_tensor = tokenizer.texts_to_sequences([test_sentence])\n",
    "    test_tensor = pad_sequences(test_tensor, maxlen=src_input.shape[1], padding='post')\n",
    "    \n",
    "    # 초기 입력\n",
    "    test_tensor = tf.convert_to_tensor(test_tensor)\n",
    "    \n",
    "    # 수정: <end> 토큰 존재 여부 확인\n",
    "    if \"<end>\" in tokenizer.word_index:\n",
    "        end_token = tokenizer.word_index[\"<end>\"]\n",
    "    else:\n",
    "        end_token = None  # <end> 토큰이 없으면 max_len까지 생성\n",
    "    \n",
    "    # 문장 생성\n",
    "    for i in range(max_len):\n",
    "        predictions = model(test_tensor)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # 가장 높은 확률의 단어 선택\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        # 종료 토큰이면 중단\n",
    "        if end_token is not None and predicted_id == end_token:\n",
    "            break\n",
    "            \n",
    "        # 예측 단어를 입력에 추가\n",
    "        test_tensor = tf.concat([test_tensor, predicted_id], axis=-1)\n",
    "    \n",
    "    # 생성된 문장을 텍스트로 변환\n",
    "    generated_sequence = test_tensor.numpy()[0]\n",
    "    generated_text = tokenizer.sequences_to_texts([generated_sequence])[0]\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# 14. 해석 가능한 문장 생성 테스트\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"가사 생성 결과 (평가기준 2)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 여러 시작 문장으로 테스트\n",
    "test_sentences = [\n",
    "    \"<start> i love\",\n",
    "    \"<start> i want\",\n",
    "    \"<start> you are\",\n",
    "    \"<start> we can\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    generated = generate_text(lyricist, tokenizer, init_sentence=sentence, max_len=20)  # 수정: model → lyricist\n",
    "    print(f\"\\n입력: {sentence}\")\n",
    "    print(f\"생성: {generated}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PDF 예시 형식 테스트\")\n",
    "print(\"=\"*50)\n",
    "result = generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"평가 기준 체크\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. 데이터 전처리: 특수문자 제거 ✓, 토크나이저 생성 ✓, 패딩 처리 ✓\")\n",
    "print(\"2. 텍스트 생성: 해석 가능한 문장 생성 (위 결과 참조)\")\n",
    "print(f\"3. 안정적 학습: Validation Loss = {min(history.history['val_loss']):.4f} (목표: 2.2 이하)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad717dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "가사 생성 결과 \n",
      "==================================================\n",
      "\n",
      "입력: <start> i love\n",
      "생성: <start> i love you , i love you end\n",
      "\n",
      "입력: <start> i want\n",
      "생성: <start> i want to diggin the scene with a gangsta lean end\n",
      "\n",
      "입력: <start> you are\n",
      "생성: <start> you are the one that i adore end\n",
      "\n",
      "입력: <start> we can\n",
      "생성: <start> we can t return , we can t be the same end\n",
      "<start> i love you , i love you end\n",
      "\n",
      "==================================================\n",
      "평가 기준 체크\n",
      "==================================================\n",
      "1. 데이터 전처리: 특수문자 제거 ✓, 토크나이저 생성 ✓, 패딩 처리 ✓\n",
      "2. 텍스트 생성: 해석 가능한 문장 생성 (위 결과 참조)\n",
      "3. 안정적 학습: Validation Loss = 0.8865 (목표: 2.2 이하)\n"
     ]
    }
   ],
   "source": [
    "# 13. 평텍스트 생성 함수 (결과가 이상해서 함수 수정)\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20):\n",
    "    # 초기 문장을 시퀀스로 변환\n",
    "    sentence = init_sentence\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        # 현재 문장을 정수 시퀀스로 변환\n",
    "        encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
    "        # 패딩\n",
    "        encoded = pad_sequences([encoded], maxlen=src_input.shape[1], padding='post')\n",
    "        \n",
    "        # 다음 단어 예측\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        \n",
    "        # 마지막 타임스텝의 예측 결과\n",
    "        result = result[0, len(tokenizer.texts_to_sequences([sentence])[0])-1, :]\n",
    "        \n",
    "        # 가장 높은 확률의 단어 선택\n",
    "        predicted_id = np.argmax(result)\n",
    "        \n",
    "        # 인덱스를 단어로 변환\n",
    "        predicted_word = None\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_id:\n",
    "                predicted_word = word\n",
    "                break\n",
    "        \n",
    "        # <end> 토큰이면 종료\n",
    "        if predicted_word == \"<end>\":\n",
    "            sentence += \" <end>\"\n",
    "            break\n",
    "        \n",
    "        # 예측된 단어를 문장에 추가\n",
    "        if predicted_word is not None:\n",
    "            sentence += \" \" + predicted_word\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# 14. 해석 가능한 문장 생성 테스트\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"가사 생성 결과 \")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 여러 시작 문장으로 테스트\n",
    "test_sentences = [\n",
    "    \"<start> i love\",\n",
    "    \"<start> i want\",\n",
    "    \"<start> you are\",\n",
    "    \"<start> we can\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    generated = generate_text(lyricist, tokenizer, init_sentence=sentence, max_len=20)  # 수정: model → lyricist\n",
    "    print(f\"\\n입력: {sentence}\")\n",
    "    print(f\"생성: {generated}\")\n",
    "\n",
    "\n",
    "result = generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"평가 기준 체크\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. 데이터 전처리: 특수문자 제거 ✓, 토크나이저 생성 ✓, 패딩 처리 ✓\")\n",
    "print(\"2. 텍스트 생성: 해석 가능한 문장 생성 (위 결과 참조)\")\n",
    "print(f\"3. 안정적 학습: Validation Loss = {min(history.history['val_loss']):.4f} (목표: 2.2 이하)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5721c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
